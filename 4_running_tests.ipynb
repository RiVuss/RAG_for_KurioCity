{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user1\\anaconda3\\envs\\RAGLLMs\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rag_objects.RAG_system_A import RAGSystemA\n",
    "from rag_objects.RAG_system_B import RAGSystemB\n",
    "from rag_objects.RAG_system_C import RAGSystemC\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "#print(torch.version.cuda)  \n",
    "#\"i'm sorry, but none of the provided locations are palaces in the hague.  the query is too specific for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing pipeline\n",
    "## Test definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_cases = [\n",
    "    {\"user_query\": \"skyscrapers in the Hague\", \"golden_route\": [\"Hoftoren\", \"Het Strijkijzer\", \"De Kroon (woontoren)\",\"Castalia (gebouw)\",\"Zurichtoren\"]},\n",
    "    {\"user_query\": \"What should a museum nerd see in Haarlem\", \"golden_route\": [\"Frans Hals Museum\", \"Verwey Museum Haarlem\", \"Teylers Museum\",\"Het Dolhuys\", \"Archeologisch Museum Haarlem\"]},\n",
    "    {\"user_query\": \"I like metro systems. Which stations are interesting in Amsterdam?\", \"golden_route\": [\"Nieuwmarkt (metrostation)\", \"Rokin (metrostation)\", \"Vijzelgracht (metrostation)\",\"Weesperplein (metrostation)\", \"Noorderpark (metrostation)\"]},\n",
    "    {\"user_query\": \"brutalist architecture Amsterdam\", \"golden_route\": [\"Hoofdgebouw Vrije Universiteit\", \"Leeuwenburg (Amsterdam)\", \"Louwesweg\",\"Kraanspoor\", \"Weteringschans 26-28\"]},\n",
    "    {\"user_query\": \"I want to see the most famous bridges of Amsterdam\", \"golden_route\": [\"Oudekerksbrug\", \"Blauwbrug\", \"Aluminiumbrug\",\"Torensluis\", \"Sint Antoniessluishoogwaterkering\"]},\n",
    "    {\"user_query\": \"the palaces of the Hague\", \"golden_route\": [\"Paleis Kneuterdijk\", \"Paleis Noordeinde\", \"Mauritshuis\",\"Paleis Huis ten Bosch\", \"Vredespaleis\"]},\n",
    "    {\"user_query\": \"What to see in Amsterdam to learn about the jewish heritage\", \"golden_route\": [\"Jodenbuurt (Amsterdam)\", \"Anne Frank Huis\", \"Nationaal Holocaustmuseum\",\"Holocaust Namenmonument\", \"Portugees-IsraÃ«lietische Synagoge\"]},\n",
    "    {\"user_query\": \"What should Rembrandt lover see in Leiden?\", \"golden_route\": [\"Latijnse school (Leiden)\", \"Rembrandtbrug\", \"Pieterskerk (Leiden)\",\"Langebrug (Leiden)\", \"Museum De Lakenhal\"]}\n",
    "]\n",
    "\n",
    "# test_cases = [\n",
    "#     {\"user_query\": \"skyscrapers in the Hague\", \"golden_route\": [\"Hoftoren\", \"Het Strijkijzer\", \"De Kroon (woontoren)\",\"Castalia (gebouw)\",\"Zurichtoren\"]},\n",
    "#     {\"user_query\": \"What should a museum nerd see in Haarlem\", \"golden_route\": [\"Frans Hals Museum\", \"Verwey Museum Haarlem\", \"Teylers Museum\",\"Het Dolhuys\", \"Archeologisch Museum Haarlem\"]}\n",
    "# ]\n",
    "\n",
    "embedding_models = {\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\": \"embeddings/all-MiniLM-L6-v2_faiss_index.index\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\": \"embeddings/all-mpnet-base-v2_faiss_index.index\",\n",
    "    \"NovaSearch/stella_en_1.5B_v5\" : \"embeddings/stella_en_1_5B_v5_embeddings_faiss_index.index\"\n",
    "}\n",
    "\n",
    "gemini_token_file = \"API_tokens/gemini.txt\"\n",
    "\n",
    "def evaluate_rag_system(rag_system, test_cases, rag_system_name, embedding_model_name, top_k=8):\n",
    "    \"\"\"\n",
    "    Evaluate a RAG system by running multiple test cases and computing retrieval metrics.\n",
    "\n",
    "    Args:\n",
    "        rag_system (RAGSystemA): The RAG system to test.\n",
    "        test_cases (list of dict): Each dict should contain:\n",
    "            - 'user_query': The query string.\n",
    "            - 'golden_route': List of ideal location titles.\n",
    "        rag_system_name (str): Name of the RAG system being tested.\n",
    "        embedding_model_name (str): Name of the embedding model used.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing results for all test cases.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        user_query = test_case[\"user_query\"]\n",
    "        golden_route = test_case[\"golden_route\"]\n",
    "        \n",
    "        # Run query\n",
    "        result = rag_system.query(user_query=user_query, top_k=top_k)\n",
    "        \n",
    "        # Extract retrieved titles\n",
    "        retrieved_titles = [loc[\"title\"] for loc in result.get(\"locations\", [])]\n",
    "        \n",
    "        # Compute golden route metrics\n",
    "        retrieved_set = set(retrieved_titles)\n",
    "        golden_set = set(golden_route)\n",
    "        common = retrieved_set.intersection(golden_set)\n",
    "        precision = len(common) / len(retrieved_titles) if retrieved_titles else 0\n",
    "        recall = len(common) / len(golden_set) if golden_set else 0\n",
    "        num_retrieved_from_golden = len(common)\n",
    "        \n",
    "        # Store results dynamically including all dictionary keys\n",
    "        result_entry = {\n",
    "            \"rag_system\": rag_system_name,\n",
    "            \"embedding_model\": embedding_model_name,\n",
    "            \"query\": user_query,\n",
    "            \"retrieved_titles\": retrieved_titles,\n",
    "            \"golden_route\": golden_route,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"num_retrieved_from_golden\": num_retrieved_from_golden,\n",
    "        }\n",
    "        \n",
    "        # Add all key-value pairs dynamically\n",
    "        for key, value in result.items():\n",
    "            if key not in result_entry:\n",
    "                result_entry[key] = value\n",
    "        \n",
    "        results.append(result_entry)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tests\n",
    "### RAG A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "RAGSystemA initialized and ready.\n",
      "Evaluating with embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "RAGSystemA initialized and ready.\n",
      "Evaluating with embedding model: NovaSearch/stella_en_1.5B_v5\n",
      "RAGSystemA initialized and ready.\n",
      "Evaluation completed. Results saved to 'test_results/A_rag_results.csv'\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for model_name, index_path in embedding_models.items():\n",
    "    print(f\"Evaluating with embedding model: {model_name}\")\n",
    "    \n",
    "    rag_system = RAGSystemA(index_path=index_path, embedding_model_name=model_name, gemini_token_file=gemini_token_file)\n",
    "    \n",
    "    # Run evaluation and collect results\n",
    "    df_results = evaluate_rag_system(rag_system, test_cases, \"RAGSystemA\", model_name, top_k=8)\n",
    "    all_results.append(df_results)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "final_results_df.to_csv(\"test_results/A_rag_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation completed. Results saved to 'test_results/A_rag_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "RAGSystemB initialized and ready.\n",
      "Evaluating with embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "RAGSystemB initialized and ready.\n",
      "Evaluating with embedding model: NovaSearch/stella_en_1.5B_v5\n",
      "RAGSystemB initialized and ready.\n",
      "Evaluation completed. Results saved to 'test_results/B_rag_results.csv'\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for model_name, index_path in embedding_models.items():\n",
    "    print(f\"Evaluating with embedding model: {model_name}\")\n",
    "    \n",
    "    rag_system = RAGSystemB(index_path=index_path, embedding_model_name=model_name, gemini_token_file=gemini_token_file)\n",
    "    \n",
    "    # Run evaluation and collect results\n",
    "    df_results = evaluate_rag_system(rag_system, test_cases, \"RAGSystemB\", model_name,top_k=16)\n",
    "    all_results.append(df_results)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "final_results_df.to_csv(\"test_results/B_rag_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation completed. Results saved to 'test_results/B_rag_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "RAGSystemC initialized and ready.\n",
      "Evaluating with embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "RAGSystemC initialized and ready.\n",
      "Evaluating with embedding model: NovaSearch/stella_en_1.5B_v5\n",
      "RAGSystemC initialized and ready.\n",
      "Evaluation completed. Results saved to 'test_results/C_rag_results.csv'\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for model_name, index_path in embedding_models.items():\n",
    "    print(f\"Evaluating with embedding model: {model_name}\")\n",
    "    \n",
    "    rag_system = RAGSystemC(index_path=index_path, embedding_model_name=model_name, gemini_token_file=gemini_token_file)\n",
    "    \n",
    "    # Run evaluation and collect results\n",
    "    df_results = evaluate_rag_system(rag_system, test_cases, \"RAGSystemC\", model_name,top_k=8)\n",
    "    all_results.append(df_results)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "final_results_df.to_csv(\"test_results/C_rag_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation completed. Results saved to 'test_results/C_rag_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGLLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
